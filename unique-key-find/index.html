<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>
      Unique Key Generation By Gap Insertion In Binary Trees
    </title>
    <link rel="stylesheet" href="styles/mono-blue.css">
    <script src="highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="bootstrap11.css">
    <script type="text/javascript" 
      src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script> 
    <script src="jquery-1.11.0.js"></script>
    <script type="text/javascript" src="sanitize.js"></script>
  </head>
  <body>

    <div class="container">
      <h1 class="title">
        Unique Key Generation By Gap Insertion In Binary Trees
      </h1>
      <p class="abstract">
        Being able to produce unique identifiers is important for many application. Currently known approaches are inadequate in many situations where efficient use of key space and guarantee of uniqueness are required. To make matters worse, uniqueness is often mistaken to be synonymous with randomness, which is simply not true. In this paper we will give a precise definition of uniqueness and develop an extension to binary tree data structure to support one more additional operation for automatic insertion into available gaps between elements of an ordered set. The presented algorithm is simple to implement and will retain all the performance characteristics and properties of binary tree without imposing any limitations. In particular the \(O \left(log {\,N} \right)\) complexity of search and insertion is preserved. Software developers already familiar with basic data structures will find this technique to be a powerful addition to their programming repertoire.

     <!--    Unarguably unique identifiers are important for many applications. Surprisingly, all currently known algorithms or techniques for generating unique identifiers suffer from many drawbacks, including among the major two, inability to guarantee uniqueness and inefficient use of key space. This paper introduces a simple method of finding unused keys in a set of used keys, bounded by a finite interval. The new algorithm is a modification of standard binary tree insertion, that performs search for gaps between keys of a tree, if found, inserts a new node into the gap. -->
      </p>
    
      <div class="content-double">
        <h2>1. Introduction</h2>
        <p>
        Occasionally on the technically minded side of the Internet a question comes up, <i>"How do I generate a unique key/number/identifier in my favorite programming language"</i>. And the usual advice on the topic varies from using a global counter variable<i>(and turning your program into a ticking bomb in best traditions of millennium bug programmers)</i> to slightly saner approach, using UUID - a gigantic 128-bit number that could as well be used to count every atom of an Earth-sized planet. Neither approach is ideal, especially for applications that create and destroy many objects quickly, where a static counter may run out of range way too quickly. Using large numbers for identifiers is part of a solution, but computers can only work efficiently with numbers of finite sizes, and so the question remains open. Is there a better way?
      </p>
      <p>
        On the other hand efficient search data structures were never in short supply, and they play an important role in optimizing countless real world applications, even those that may not appear as search problems at first glance. It's an accepted fact of life, that if a problem can be reduced to a search in ordered set, it's almost certain it can be done fast with a binary tree or similar data structure. Search for a unique key is one of those problems.
      </p>
      <p>
        The method presented here, may not be a silver bullet yet, but it might benefit those applications already relying on symbol tables, and more over it reveals an interesting direction that might be worth exploring further in other contexts.
      </p>
      <h2>2. Definitions</h2>
      <p>
        Before we introduce the actual algorithm for finding <i>unique keys</i>, let's define the problem and it's solution in abstract terms. Most of the terminology here is based on basic <i>set theory</i>.
      </p>
      <p>
        Let set \(S\) be a set of all valid keys. This set need not be defined explicitly, it's much more compact and useful to define it as an interval between some <i>minimum</i> and <i>maximum</i>.

        \[S = (Min, Max)\]
        
        Then lets suppose we marked some keys to have certain property, for instance property of being <i>used</i>. Let's define subset \(K\) of \(S\) to be the set of all keys possessing that property.

        \[K= \{ x\in S\,|\,P(x)\} \]
 
        \[K \subseteq S \]

        Then the set \(K'\) of all keys <i>not</i> possessing the property, naturally, is <i>complementary</i> to \(K\) and is also a <i>subset</i>.
        \[K'= \{ x\in S\,|\, \neg \, P(x)\} \]
        \[K'=S \setminus K; \, K \subseteq S \]
        
        <p>
        If we define a <i>unique key</i>, as any key that's <i>not used</i>, then set \(K'\) is a set of all <i>unique keys</i>. If that definition is accepted to be <i>true</i>, then all it takes to produce a <i>unique key</i>, is to find <i>any</i> element of the <i>complementary</i> set \(K'\) and possibly <i>move</i> it into the set \(K\), in the event if we wanted to mark it as <i>not</i> being <i>unique</i> anymore.
        </p>

        <p>
        This whole operation can be abstractly defined as a function that <i>transfers</i> elements one at a time between two <i>complementary</i> portions \(X\) and \( (U \setminus X) \) of some set \(U\).
        \[ f:(X,U) \rightarrow (Y, y)\]
        \[Where \enspace  X \neq U;\, y \in Y;\, y \in (U \setminus X);\, X \in Y \in U\]
        Such function produces a new set \(Y\) containing one more element \(y\), that was previously in the complementary set. We will be referring to this function as <i>complementary transfer function</i>.
        </p>
        <p>
          If all the sets are defined as ordered, then a <i>gap</i> is any set of <i>adjacent</i> keys in set \(S\) that are also members of <i>complementary</i> set \(K'\). A <i>union</i> of all <i>gaps</i> is <i>equivalent</i> to the <i>complementary</i> set \(K'\). A set of all <i>gaps</i> is also formally speaking an instance of a <i>set partition</i> of \(K'\).
        </p>
        <p>
          More intuitively a set of all gaps can be produced by slicing the interval \((Min, Max)\) by every element of \(K\), the resulting set of intervals would be the set of <i>gaps</i>.
        </p>
        <p>
          A size of set \(K\) is simply number of elements in set \(K\), or \( \left| K \right| \) &ndash; set <i>cardinality</i>. 
        </p>
        <p>
          We will refer to <i>space</i> as size of <i>complementary</i> set \(K'\), or \( \left| K' \right| \), indicating how many more elements are possible to transfer.
        </p>
        <h2>2. Implementing Complementary Transfer Function </h2>
        <p>
          The complementary transfer function defined previously, only states what it does, not how it does it. The biggest difficulty in implementing such a function is finding elements of complementary set \(K'\), and doing so efficiently.
        </p>
        <p>
          It was stated, that complementary set \(K'\) can be expressed in terms of <i>gaps</i>. Searching for gaps can be far more efficient than searching for individual elements of set \(K'\). In this section we will define one complete implementation of complementary transfer function, based on a binary tree insertion operation.
        </p>
        <p>
          <s>All the definitions above would be useless if there was no way to actually find a <i>gap</i>. In this section we will derive an algorithm that can be used to efficiently search for those gaps.</s> We will start by considering the obvious approach first and explain why it wouldn't work, then move on to a more practical solution.
        </p>
        <p>
          A <i>binary tree</i> is a search-efficient representation of a <i>totally ordered</i> set. A <i>balanced</i> binary tree guarantees <i>worst case</i> time of search to be \( O \left( log {\,N} \right) \). Three most basic operations on binary trees are: <i>search, insert</i> and <i>remove</i>. The simplest of them all is search. <i>Removing</i> and <i>inserting</i> is more difficult, because it can potentially produce an <i>unbalanced</i> tree, and special measures are required to counteract or minimize chances of this happening. Even though more difficult, <i>insertion</i> and <i>removal</i> can be done in <i>logarithmic time</i>. 
        </p>
        <p>
          A standard insertion function in a binary tree, first, performs a search for a key, if it finds the key it leaves the tree unchanged, otherwise it creates a new node at the place where key was supposed to be found and performs balancing restructuring if necessary.
        </p>
        <p>
          In order to implement the <i>complementary transfer function</i> with a binary tree all we have to do, is take the standard insertion function as basis and replace the <i>search criteria</i> for <i>key</i> with <i>search criteria</i> for <i>any non-empty gaps</i>. With the exception of an additional parameter &mdash; the interval defining set \(S\), everything else can be left the same. <i>Complementary transfer function</i> is simply <i>gap insertion</i>.
        <p>
        <p>
          As an example consider a <i>hypothetical</i> tree, where number of gaps is available at each node in <i>constant time</i>:
         
          \[N\, =\, \{ \,1,\,2,\,5,\,6,\,10,\,11,\,13\,\} \]
          \[S = (0, 15)\]
          
          <img src="gapaug.png" width="400px"/>
          <p class="figure-dscr"> Figure 1: Gap-augmented tree </p>
        <p>
          Search for gap in such tree is trivial, and can be accomplished by <i>recursively</i> following any tree branch that has <i>gaps</i>, until encountering an <i>empty link</i>. <i>Insertion</i> can than proceed as normal, by creating a new node. Below is a sketch of how such an algorithm might look, in real implementation more care must be taken to consider edge cases, but this pseudo-code should be sufficient enough to show simplicity of the concept.
        </p>
        <p>
<pre><code>
-- Pseudo-code for abstract gap insertion

Gap-Insert(Node) -> Key {
  if (Node Is Leaf):
    Insert Here 
    Return Key
  else
    if(Left Node Has Gaps):
      Go Left
    else if (Right Node Has Gaps):
      Go Right
    else:
      Fail, No Space
}

</code></pre>
        </p>
        <p>
          <i>Augmenting</i> tree nodes is common technique that allows storing values in tree nodes in order to make them accessible in <i>constant time</i> later. It's easy enough to compute in advance any attribute you might want to associate with a node, especially if performance is not an issue or if updating is not required. Our use case of binary trees unfortunately falls in neither of those categories, and more care must be taken of what can be stored at the nodes.
        </p>
        <p>
          Updating <i>augmented</i> values can be done <i>efficiently</i> only for values that depend on the <i>node itself</i> and immediate values of it's <i>child nodes</i>. Such values propagate <i>upward</i> from the source of change, but never <i>below</i>. Since every node can only have one <i>parent</i>, that means any change will only have to propagate upward through single path in a tree, preserving the \( O \left( log {\,N} \right) \) complexity. A good example of upward-propagating value<i>(and a one we will need later)</i> is <i>size</i>:

          \[ Node.Size = Node.Left.Size + 1 + Node.Right.Size \]

          Tree <i>size</i> is usually straightforward to update during <i>insertion</i> and <i>removing</i>.
        </p>
        <p>
          On the other hand, values that may be affected by <i>parent nodes</i> cannot be updated efficiently, because every node has two <i>children</i>, <i>doubling</i> the amount of updates that have to be done for each node passed. In worst case, entire tree would have to be updated, destroying any guarantee of <i>logarithmic time</i>. Such values propagate <i>downwards</i> or even <i>both</i> ways. Gap counts happen to be propagating in this manner.
        </p>
        <p>
          Consider what happens with gaps when changing a value of a node at the top, a common occurrence that might happen during balancing or removing. All the binary tree invariants are still preserved and if no gap information was stored we could safely stop at this point without violating integrity of the data structure. The gaps however did <i>not</i> preserve and need updating!
        </p>
        <img src="gapupdate.png" width="400px"/>
        <p class="figure-dscr"> Figure 2: Difficulty of updating gap-augmented tree </p>
        <p>
          Pictured above is the result of replacing node \(6\) with node \(7\). All the paths and nodes that had to be updated are marked in red. Clearly counting gaps explicitly, like we count nodes in a size-augmented tree, is not a good approach in this situation. This particular case was lucky to get \( O \left( 2log {\,N} \right) \) complexity, since update propagates down to only two paths. Still any real balancing algorithm would cause havoc to such tree. Not only it would be leaking performance everywhere it matters, but it would also be insanely difficult to implement. 
        </p>
        <p>
          Fortunately, there's another way to deduce number of <i>gaps</i> in each subtree, based on binary tree invariants, that doesn't involve explicit counting. Those two important invariants are:
          <ul style="font-style: italic;">
            <li>If node \(X\) is the <i>left</i> child of node \(Y\), value of \(X\) is <i>less</i> than value of \(Y\)</li>
            <li>If node \(Z\) is the <i>right</i> child of node \(Y\), value of \(Z\) is <i>bigger</i> than value of \(Y\)</li>
          </ul>
        </p>
        <p>
          It may not be immediately obvious, but these two invariants can be generalized to make assertions on entire subtrees:
        </p>
        <ul style="font-style: italic;">
          <li> For every node \(X \,|\, X \in\) <i>left subtree</i> of \(Y\), value of \(X\) is <i>less</i> than value of \(Y\)</li>
          <li> For every node \(Z \,|\, Z \in\) <i>right subtree</i> of \(Y\), value of \(Z\) is <i>bigger</i> than value of \(Y\)</li>
        </ul>
        <p>
          This fact allows us to define bounding interval \(S\) recursively for each subtree. If you've been waiting for the punchline, this is it.
        </p>
        <p>
          Let \(y\) be the value of node \(Y\) and \(S_{y} = (Min, Max)\) be a bounding interval defining valid potential keys of subtree beginning at node \(Y\), then following two rules can be observed:
        </p>
          <ul style="font-style: italic;">
            <li>
              If node \(X\) is the <i>left</i> child of \(Y\), then bounding interval of \(X\) is \(S_{x} = (Min, y) \)
            </li>
            <li>
              If node \(Z\) is the <i>right</i> child of \(Y\), then bounding interval of \(Z\) is \(S_{z} = (y, Max) \)
            </li>
          </ul>
        <img src="boundaries.png" width="400px"/>
        <p>
          We will be referring to the above rules as <i>boundary propagation</i> rules, they allow us to construct set <i>boundary</i> \(S\) at each node, given we know <i>boundary</i> of it's parent. 
        </p>
        <p>
          In order to implement boundary propagation all we have to do is alter the bounding interval \(S\) during each recursive call or loop iteration. Since search will only travel down a single path in a tree we only require knowing boundaries along that path and no other.
        </p>
        <p>
          Our <i>abstract gap search</i> algorithm relied on the fact that <i>gap count</i> is accessible at each node in <i>constant time</i>. Following from previous definitions, <i>gap count</i> is simply the <i>cardinality</i>(set size) of <i>complementary</i> set \(K'\), the set difference.
          \[\left| K' \right| = \left| \, S \setminus K \, \right| \]
        </p>
        <p>
          Cardinality of set difference is also, intuitively, same as difference of cardinalities. Making it possible to deduce cardinality of complementary set \(K'\) from cardinalities of sets \(S\) and \(K\):
          \[\left| K' \right| = \left| \, S \, \right| - \left| \, K \, \right| \]
        </p>
        <p font-style: italic;>
          The last statement can be more intuitively thought of as a difference between number of nodes tree can <i>potentially</i> have and number of nodes it <i>actually</i> has. That difference is the total number of gaps in a subtree:
        </p>
        <p class="statement">
          Number Of Gaps = Potential Size - Actual Size
        </p>
        <p>
          Where <i>actual size</i> is number of nodes augmented at each node, as was described before and available in <i>constant time</i>. Potential size is simply size of <i>open interval</i> of valid possible keys:

          \[
          f \left(A,\,B \right) = \left\{\begin{array}{ll}
          B-A-1 & : A \lt B \\
          0 & : A = B
          \end{array}
          \right.
          \]
        </p>
        <p>
          We now have all the elements needed to turn the <i>abstract gap insertion</i> algorithm into a real one. At each node \(X\) we know boundaries of set \(S_{x}\) defining it's <i>potential range</i> of keys, thanks to<i> boundary propagation</i> rules. Knowing set \(S_{x}\) we can compute it's <i>size</i> with a simple arithmetic function, yielding <i>potential size</i> of a subtree at \(X\). The whole computation of <i>potential size</i> is therefore in <i>constant time</i>, since it relies only on local, readily available data. Then all that remains to compute number of <i>gaps</i> at this point is knowing the <i>actual size</i> of a subtree. We make <i>actual size</i> available in <i>constant time</i> by <i>storing</i> it at each node. <i>Number of gaps</i> at the subtree is then computed as a <i>difference</i> between <i>potential</i> and <i>actual</i> size.
        </p>
        <p>
          Thus we have fulfilled the basic assumption of our <i>abstract gap insertion</i> algorithm that the <i>gap counts</i> are available in <i>constant time</i> and we can define a more sophisticated algorithm that doesn't require gap counts to be stored at each node:
        </p>
<pre><code>
-- Pseudo-code for gap insertion using boundary propagation

Gap-Insert(Node, Min, Max) -> (Node, Key) {
  if (Gaps > 0):
    if (Node Is Leaf):
      Pick Any Key In Gap Range (Min, Max)
      Create A Node With That Key
      Return (Inserted-Node, Inserted-Key)
    else:
      Go Left  With Max = Node.Key
      Go Right With Min = Node.Key, if left insertion failed
      Update Node Size and Links
      Return (Updated-Node, Inserted-Key)
  else:
    Return (Node, Key)
  where
    Gaps = Interval-Size(Min, Max) - Node.Size 
}

</code></pre>
        <h2>3. Implementations</h2>
        <p>
          With definitions done and the algorithm clearly defined and rationalized, we can finally be at our leisure and complete a few implementations in real programming languages. In this section we will present both recursive and non-recursive implementations of gap insertion and then showcase a couple of useful abstract data structures that rely on gap insertion.
        </p>
        <p>
          For our first recursive implementation we will choose <i>Haskell</i> &mdash; it's support for pattern matching and lazy evaluation make writing recursive code a breeze. Below is the source code for gap insertion and it's supporting code:
        </p>
        <!-- Haskell implementation -->
<pre><code>
From file: EnumRanges.hs  (<a href="rbst.html">view</a>)

middleEnum :: (Enum a) => a -> a -> a
middleEnum a b =
  toEnum(ia + (ib - ia) `div` 2)
  where
    ia = fromEnum a
    ib = fromEnum b

enumsBetween :: (Enum a, Eq a) => a -> a -> Int
enumsBetween a b
  | a == b = 0
  | otherwise = (enumDistance a b) - 1

</code></pre>

<pre><code>
From file: RBST.hs  (<a href="rbst.html">view</a>)

import Data.Maybe
import Enum.Ranges

data Tree a = E | T (Tree a) a (Tree a) Int deriving (Show)

size (T _ _ _ s) = s
size E = 0

gapInsert' :: (Enum a, Eq a) => Tree a -> a -> a -> (Tree a, Maybe a)
gapInsert' tr min max
  | gaps > 0 = 
      case tr of
        E ->
          let 
            k = middleEnum min max
            in ((T E k E 1), Just k)
        T l k r _ -> 
          let
            ns = size(nl) + 1 + size(nr)
            (nl, nr, ik) = 
              let
                (li, lik) = (gapInsert' l (min) (k))
                (ri, rik) = (gapInsert' r (k) (max))
              in
                if(isJust lik)
                  then (li, r, lik)
                  else (l, ri, rik)
            in ((T nl k nr ns), ik)
  | otherwise = (tr, Nothing)
  where
    gaps = (enumsBetween min max) - size(tr)

</code></pre>
       <p>
         First note that the type signature of function <i>gapInsert</i> corresponds almost one to one to the <i>complementary transfer function</i> we defined earlier:
         \[ f:(X,U) \rightarrow (Y, y)\]
       </p>
       <p>
         Here set \(X\) corresponds to the first argument, a binary tree. Set \(U\) are all the valid potential keys and correspond to <i>open interval</i> defined from <i>min</i> to <i>max</i>. Set \(Y\) is super set of \(X\) with one more element \(y\) transfered from set \(U \setminus X\), set \(Y\) correspons to the modified tree being returned as the first element of a tuple, and element \(y\) corresponds to the second element wrapped in a <i>Maybe</i> type. 

        <p>
          The only difference is that <i>complementary transfer function</i> is not defined when complementary set \(U \setminus X\) is <i>empty</i> (i.e when \(U = X\)). This makes it's definition succint, but a more useful function would be defined for the whole <i>domain</i>, not just part of it. That's why we use <i>Maybe</i> type to return <i>Nothing</i> instead of \(y\) when set \(U \setminus X\) is <i>empty</i>, and <i>Just</i> \(y\), when it's <i>not</i>. 
       </p>
       <p>
          Exploring type signature further, note that the keys and boundaries are restricted to <i>Enum</i> and <i>Eq</i> class, this is unusual for an insert function. A regular insert function would restrict keys to <i>Ord</i> class and nothing else. While <i>Eq</i> and <i>Ord</i> classes can be interchanged, the reason for <i>Enum</i> is more profound. Remember that in order to insert into a gap between two keys, we have to produce a key on that interval, and that key is not known in advance, it has to be produced. If keys were guaranteed to be numbers, it would be trivial, but it's not necessary to restrict possible types so much especially in Haskell where <i>Enum</i> interface is available, which represents a general notion of a <i>countable</i> type. 
       </p>
       <p>
          It is with that goal of generality in mind we use function <i>middleEnum</i> to produce keys within gap interval, and function <i>enumsBetween</i> when computing size of open interval, instead of normal arithmetic functions, which would restrict key type unnecessarily. 
       </p>
       <p>
          The last unusual artifact of the implementation is it's use of <i>lazy evaluation</i> and <i>pattern matching</i>, as a way of streamlining the code. This is manifested a dense block of pattern matched tuples with some conditional evaluation:
       </p>
<pre><code>
let
  ns = size(nl) + 1 + size(nr)
  (nl, nr, ik) = 
    let
      (li, lik) = (gapInsert' l (min) (k))
      (ri, rik) = (gapInsert' r (k) (max))
    in
      if(isJust lik)
        then (li, r, lik)
        else (l, ri, rik)
  in ((T nl k nr ns), ik)

</code></pre>
       <p>
         Here results of left and right insertions are destructed and bound to names. Since Haskell is a <i>lazy</i> language, insertions are <i>not</i> actually evaluated <i>unless/until</i> they are <i>needed</i>. If you want a challenge, you can attempt to untangle those definitions in a strict language. Without using lazy evaluation, it will not look as good, or be as readable.
       </p>
       <p>
         One problem with this implementation is that it favors <i>left</i> branches, so it has tendency to produce <i>unbalanced</i> trees. There are multiple ways that could be resolved, one is to use <i>self-balancing</i> trees, among which are the messy, but popular <i>Red-Black</i> trees, just as messy, but less popular <i>AVL</i> trees, and simpler and almost unknown <i>AA</i> trees. Even better approach is to just <i>randomize</i> path choice whether gaps are available on <i>both</i> sides. In regular insertion this would be impossible, as key to be inserted is known in advance, but for gap insertion we are not bound to pick any specific key.
       </p>
       <p>
         A second implementation of gap insertion is provided that uses <i>random number generator</i> to resolve ties. Since Haskell is a <i>pure</i> language we need modify function definition to accept <i>state</i> of a <i>random generator</i> and then return a new <i>state</i> after it was used, we also need to be careful to propagate generator states returned from recursive calls:
       </p>
<pre><code>
From file: RBST.hs  (<a href="rbst.html">view</a>)

gapInsert :: (Enum a, Eq a, <strong>RandomGen g</strong>) => <strong>g</strong> -> Tree a -> a -> a -> (<strong>g</strong>, Tree a, Maybe a)
gapInsert <strong>g</strong> tr min max
  | gaps > 0 = 
      case tr of
        E ->
          let 
            k = middleEnum min max
            in (<strong>g</strong>, (T E k E 1), Just k)
        T l k r _ -> 
          let
            ns = size(nl) + 1 + size(nr)
            (<strong>eg</strong>, nl, nr, ik) = 
              let
                <strong>(bias, ng) = random g</strong>
                (<strong>lg</strong>, li, lik) = (gapInsert ng l (min) (k))
                (<strong>rg</strong>, ri, rik) = (gapInsert ng r (k) (max))
                left = <strong>(bias && isJust lik) || (not bias && isNothing rik)</strong>
              in
                if(left)
                  then (<strong>lg</strong>, li, r, lik) 
                  else (<strong>rg</strong>, l, ri, rik)
            in (<strong>eg</strong>, (T nl k nr ns), ik)
  | otherwise = (<strong>g</strong>, tr, Nothing)
  where
    gaps = (enumsBetween min max) - size(tr)

</code></pre>
       <p>
         A boolean function is used to select left branch if it's successful and biased or if it's not biased, but right branch wasn't successful:
         \[
           f\left(B, L, R \right)  = \left(B \wedge L \right) \vee \left(\neg B \wedge  \neg R \right)
         \]
       </p>
        <table>
          <thead>
            <tr>
              <td>\(B\)</td><td>\(L\)</td><td>\(R\)</td><td>\( f \)</td>
            </tr>
          </thead> 
          <tbody>
            <tr>
              <td class="T">\(T\)</td><td class="T">\(T\)</td><td class="T">\(T\)</td><td class="T">\( T \)</td>
            </tr>
            <tr>
              <td class="T">\(T\)</td><td class="T">\(T\)</td><td class="F">\(F\)</td><td class="T">\( T \)</td>
            </tr>
            <tr>
              <td class="T">\(T\)</td><td class="F">\(F\)</td><td class="T">\(T\)</td><td class="F">\( F \)</td>
            </tr>
            <tr>
              <td class="T">\(T\)</td><td class="F">\(F\)</td><td class="F">\(F\)</td><td class="F">\( F \)</td>
            </tr>
            <tr>
              <td class="F">\(F\)</td><td class="T">\(T\)</td><td class="T">\(T\)</td><td class="F">\( F \)</td>
            </tr>
            <tr>
              <td class="F">\(F\)</td><td class="T">\(T\)</td><td class="F">\(F\)</td><td class="T">\( T \)</td>
            </tr>
            <tr>
              <td class="F">\(F\)</td><td class="F">\(F\)</td><td class="T">\(T\)</td><td class="F">\( F \)</td>
            </tr>
            <tr>
              <td class="F">\(F\)</td><td class="F">\(F\)</td><td class="F">\(F\)</td><td class="T">\( T \)</td>
            </tr>
          </tbody>
        </table>
       <p>
         Special care must be taken to not accidentally evaluate result of relatively expensive insertion and then discard it! The boolean function is constructed in such a way that, it will never cause evaluation down unnecessary path. The only time evaluation results are being discarded is when <i>bias</i> is on the side that has no <i>gaps</i>, and evaluates to <i>Nothing</i>. This however is not a problem, since insertion into a tree that has no <i>gaps</i> is a <i>constant time</i> operation, not <i>logarithmic</i>, so no expensive computation is being discarded.
       </p>
       <p>
         While Haskell looks beautiful on paper, it's not very efficient and it's not the first choice when it comes to speed. For non-recursive high performance implementation we will use C:
       </p>
<pre><code>
From file: rbst.h (<a href="rbst.html">view</a>)

struct RBST {
  struct RBSTNode* root;
  int min;
  int max;
  int MAX_DEPTH;
};

struct RBSTNode {
  int key;
  void* value;
  struct RBSTNode* links[2];
  int count;
};

</code></pre>

<pre><code>
From file: rbst.c (<a href="rbst.html">view</a>)

int rbst_gap_insert(struct RBST* tree, void* value)
{
  assert(tree);
  
  // initial boundaries
  int min = tree->min;
  int max = tree->max;

  // check if tree has any gaps at all
  if((keys_between(min, max) - count(tree->root)) == 0)
  {
    return 0;
  }
  
  // handle special case when root is NULL
  if(tree->root == NULL)
  {
    int key = middle(min, max);
    tree->root = create_node(key, value);
    return key;
  }

  // find any node adjacent to a gap
  // store node at "it" and gap boundaries in "min", "max"
  int dir;
  struct RBSTNode* it = tree->root;
  for(;;) {
    int bias = rnd_bool();
    int gaps_left = keys_between(min, it->key) - count(it->links[0]);
    int gaps_right = keys_between(it->key, max) - count(it->links[1]);

    // select any branch having gaps, select randomly if both available
    dir = (!bias && !(gaps_left > 0)) || (bias && (gaps_right > 0));

    // apply boundary propagation rules
    if(!dir) 
      max = it->key; 
    else
      min = it->key;

    // increment actual size, since we know gap is available somewhere
    // and insertion is guaranteed to succeed along this path
    it->count++;

    // check if current node has open link on the side of gap
    if(it->links[dir] == NULL)
      break;

    // continue along branch where gaps are
    it = it->links[dir];
  }

  // select any key from the gap and create node there
  int key = middle(min, max);
  it->links[dir] = create_node(key, value);

  return key;
}

</code></pre>
       <p>
        The first thing we do in this implementation, is check if tree has any <i>gaps</i>. If it doesn't there's no point in continuing, if there's at least one gap available, we can be assured from there on that we can find it. This assumption allows us to start incrementing node sizes along path being traversed, even before we actually insert something! If we couldn't make such an assumption, we would have to maintain an explicit stack for nodes traversed.
       </p>
       <p>
        The loop is meant to take us to the point next to insertion, it will also indicate a direction where gap is, and provide values for bounding interval. When we exit loop, all we have to do is pick a new key within the bounding interval, create a new  node and update parent's link.
       </p>
      <!-- Okey, just be precise, define unique, what are we looking for etc. in terms of sets. Then define data structures briefly and show they normal form. Then show the modified form. That's all.  -->

      
      


        <!-- Introduction to current state of art
        Binary tree, skip lists all that jazz too
 -->
        <!-- Definitions
        What is unique, what are we looking for

        Gap Insertion For Skip lists
        Normal Insertion

        Gap Insertion For Binary trees
        Normal Insertion -->

        
      </div>
    </div>
  </body>
</html>

<!-- 
  
  Title
  Abstract
  Contents (Simple)
  MathJax
  Highlight.js

 


 -->
