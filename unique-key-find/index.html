<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>
      Unique Key Generation By Gap Insertion In Skip Lists And Binary Trees
    </title>
    <link rel="stylesheet" href="styles/mono-blue.css">
    <script src="highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="bootstrap11.css">
    <script type="text/javascript" 
      src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script> 
    <script src="jquery-1.11.0.js"></script>
    <script type="text/javascript" src="sanitize.js"></script>
  </head>
  <body>

    <div class="container">
      <h1 class="title">
        Unique Key Generation By Gap Insertion
      </h1>
      <p class="abstract">
        Being able to produce unique identifiers is important for many application. Currently known approaches are inadequate in many situations where efficient use of key space and guarantee of uniqueness are required. To make matters worse, uniqueness is often mistaken to be synonymous with randomness, which is simply not true. In this paper we will give a precise definition of uniqueness and develop an extension to binary tree data structure to support one more additional operation for automatic insertion into available gaps between elements of an ordered set. The presented algorithm is simple to implement and will retain all the performance characteristics and properties of binary tree without imposing any limitations. In particular the \(O \left(log {\,N} \right)\) complexity of search and insertion is preserved. Software developers already familiar with basic data structures will find this technique to be a powerful addition to their programming repertoire.

     <!--    Unarguably unique identifiers are important for many applications. Surprisingly, all currently known algorithms or techniques for generating unique identifiers suffer from many drawbacks, including among the major two, inability to guarantee uniqueness and inefficient use of key space. This paper introduces a simple method of finding unused keys in a set of used keys, bounded by a finite interval. The new algorithm is a modification of standard binary tree insertion, that performs search for gaps between keys of a tree, if found, inserts a new node into the gap. -->
      </p>
    
      <div class="content-double">
        <h2>1. Introduction</h2>
        <p>
        Occasionally on the technically minded side of the Internet a question comes up, <i>"How do I generate a unique key/number/identifier in my favorite programming language"</i>. And the usual advice on the topic varies from using a global counter variable<i>(and turning your program into a ticking bomb in best traditions of millennium bug programmers)</i> to slightly saner approach, using UUID - a gigantic 128-bit number that could as well be used to count every atom of an Earth-sized planet. Neither approach is ideal, especially for applications that create and destroy many objects quickly, where a static counter may run out of range way too quickly. Using large numbers for identifiers is part of a solution, but computers can only work efficiently with numbers of finite sizes, and so the question remains open. Is there a better way?
      </p>
      <p>
        On the other hand efficient search data structures were never in short supply, and they play an important role in optimizing countless real world applications, even those that may not appear as search problems at first glance. It's an accepted fact of life, that if a problem can be reduced to a search in ordered set, it's almost certain it can be done fast with a binary tree or similar data structure. Search for a unique key is one of those problems.
      </p>
      <p>
        The method presented here, may not be a silver bullet yet, but it might benefit those applications already relying on symbol tables, and more over it reveals an interesting direction that might be worth exploring further in other contexts.
      </p>
      <h2>2. Definitions</h2>
      <p>
        Before we introduce the actual algorithm for finding <i>unique keys</i>, let's define the problem and it's solution in abstract terms. Most of the terminology here is based on basic <i>set theory</i>.
      </p>
      <p>
        Let set \(S\) be a set of all valid keys. This set need not be defined explicitly, it's much more compact and useful to define it as an interval between some \(Minimum\) and \(Maximum\).

        \[S = (Minimum, Maximum)\]
        
        Then lets suppose we marked some keys to have certain property, for instance property of being <i>used</i>. Let's define subset \(K\) of \(S\) to be the set of all keys possessing that property.

        \[K= \{ x\in S\,|\,P(x)\} \]
 
        \[K \subseteq S \]

        Then the set \(K'\) of all keys <i>not</i> possessing the property, naturally, is <i>complementary</i> to \(K\) and is also a <i>subset</i>.
        \[K'= \{ x\in S\,|\, \neg \, P(x)\} \]
        \[K'=S \setminus K; \, K \subseteq S \]
        
        <p>
        If we define a <i>unique key</i>, as any key that's <i>not used</i>, then set \(K'\) is a set of all <i>unique keys</i>. If that definition is accepted to be <i>true</i>, then all it takes to produce a <i>unique key</i>, is to find <i>any</i> element of the <i>complementary</i> set \(K'\) and possibly <i>move</i> it into the set \(K\), in the event if we wanted to mark it as <i>not</i> being <i>unique</i> anymore.
        </p>

        <p>
        This whole operation can be abstractly defined as a function that <i>transfers</i> elements one at a time between two <i>complementary</i> portions \(X\) and \( (U \setminus X) \) of some set \(U\).
        \[ f:(X,U) \rightarrow (Y, y)\]
        \[Where\, y \in Y \wedge y \in (U \setminus X) \wedge X \in Y \in U\]
        IF complementary set is not empty!
        Such function produces a new set \(Y\) containing one more element \(y\), that was previously in the complementary set. We will be referring to this function as <i>complementary transfer function</i>.
        </p>
        <p>
          If all the sets are defined as ordered, then we can say that set \(K\) partitions set \(S\) into a set of gaps \(G\). A union of all gaps is equivalent to the complementary set \(K'\). 
          \[\bigcup _{ \,X\, \in \, G }{ X } = \,K'\]
          Formally speaking \(G\) is an instance of a <i>set partition</i> of \(K'\).
        </p> 
        <p>
          A more rigorous definition of set G would be awkward and wouldn't provide much in terms of insight. The intuitive image is to think of slicing the interval \((Minimum, Maximum)\) by every element of \(K\) &mdash; the resulting set of intervals would be the set of gaps \(G\).
        </p>
        <p>
          In this way we defined the complementary set \(K'\) in terms of slices of interval \((Minimum, Maximum)\) representing set \(S\), or in terms of <i>gaps</i>. That means all <i>unique keys</i> can be found in <i>gaps</i> between elements of a set \(K\).
        </p>
        <h2>2. Gap Search</h2>
        <p>
          All the definitions above would be useless if there was no way to actually find a <i>gap</i>. In this section we will derive an algorithm that can be used to efficiently search for those gaps. We will start by considering the obvious approach first and explain why it wouldn't work, then move on to a more practical solution.
        </p>
        <p>
          A <i>binary tree</i> is a search-efficient representation of a <i>totally ordered</i> set. A <i>balanced</i> binary tree guarantees <i>worst case</i> time of search to be \( O \left( log {\,N} \right) \). Three most basic operations on binary trees are: <i>search, insert</i> and <i>remove</i>. The simplest of them all is search. <i>Removing</i> and <i>inserting</i> is more difficult, because it can potentially produce an <i>unbalanced</i> tree, and special measures are required to counteract or minimize chances of this happening. Even though more difficult, <i>insertion</i> and <i>removal</i> can be done in <i>logarithmic time</i>. 
        </p>
        <p>
          A standard insertion function in a binary tree, first, performs a search for a key, if it finds the key it leaves the tree unchanged, otherwise it creates a new node at the place where key was supposed to be found and performs balancing restructuring if necessary.
        </p>
        <p>
          In order to implement the <i>complementary transfer function</i> with a binary tree all we have to do, is take the standard insertion function as basis and replace the <i>search criteria</i> for <i>key</i> with <i>search criteria</i> for <i>any non-empty gaps</i>. With the exception of an additional parameter &mdash; the interval defining set \(S\), everything else can be left the same. <i>Complementary transfer function</i> is simply <i>gap insertion</i>.
        <p>
        <p>
          As an example consider a <i>hypothetical</i> tree, where number of gaps is available at each node in <i>constant time</i>:
         
          \[N\, =\, \{ \,1,\,2,\,5,\,6,\,10,\,11,\,13\,\} \]
          \[S = (0, 15)\]
          
          <img src="gapaug.png" width="400px"/>
          <p class="figure-dscr"> Figure 1: Gap-augmented tree </p>
        <p>
          Search for gap in such tree is trivial, and can be accomplished by <i>recursively</i> following any tree branch that has <i>gaps</i>, until encountering an <i>empty link</i>. <i>Insertion</i> can than proceed as normal, by creating a new node. Below is a sketch of how such an algorithm might look, in real implementation more care must be taken to consider edge cases, but this pseudo-code should be sufficient enough to show simplicity of the concept.
        </p>
        <p>
<pre><code>
-- Pseudo-code for abstract gap insertion

Gap-Insert(Node) -> Key {
  if (Node Is Leaf):
    Insert Here 
    Return Key
  else
    if(Left Node Has Gaps):
      Go Left
    else if (Right Node Has Gaps):
      Go Right
    else:
      Fail, No Space
}

</code></pre>
        </p>
        <p>
          <i>Augmenting</i> tree nodes is common technique that allows storing values in tree nodes in order to make them accessible in <i>constant time</i> later. It's easy enough to compute in advance any attribute you might want to associate with a node, especially if performance is not an issue or if updating is not required. Our use case of binary trees unfortunately falls in neither of those categories, and more care must be taken of what can be stored at the nodes.
        </p>
        <p>
          Updating <i>augmented</i> values can be done <i>efficiently</i> only for values that depend on the <i>node itself</i> and immediate values of it's <i>child nodes</i>. Such values propagate <i>upward</i> from the source of change, but never <i>below</i>. Since every node can only have one <i>parent</i>, that means any change will only have to propagate upward through single path in a tree, preserving the \( O \left( log {\,N} \right) \) complexity. A good example of upward-propagating value<i>(and a one we will need later)</i> is <i>size</i>:

          \[ Node.Size = Node.Left.Size + 1 + Node.Right.Size \]

          Tree <i>size</i> is usually straightforward to update during <i>insertion</i> and <i>removing</i>.
        </p>
        <p>
          On the other hand, values that may be affected by <i>parent nodes</i> cannot be updated efficiently, because every node has two <i>children</i>, <i>doubling</i> the amount of updates that have to be done for each node passed. In worst case, entire tree would have to be updated, destroying any guarantee of <i>logarithmic time</i>. Such values propagate <i>downwards</i> or even <i>both</i> ways. Gap counts happen to be propagating in this manner.
        </p>
        <p>
          Consider what happens with gaps when changing a value of a node at the top, a common occurrence that might happen during balancing or removing. All the binary tree invariants are still preserved and if no gap information was stored we could safely stop at this point without violating integrity of the data structure. The gaps however did <i>not</i> preserve and need updating!
        </p>
        <img src="gapupdate.png" width="400px"/>
        <p class="figure-dscr"> Figure 2: Difficulty of updating gap-augmented tree </p>
        <p>
          Pictured above is the result of replacing node \(6\) with node \(7\). All the paths and nodes that had to be updated are marked in red. Clearly counting gaps explicitly, like we count nodes in a size-augmented tree, is not a good approach in this situation. This particular case was lucky to get \( O \left( 2log {\,N} \right) \) complexity, since update propagates down to only two paths. Still any real balancing algorithm would cause havoc to such tree. Not only it would be leaking performance everywhere it matters, but it would also be insanely difficult to implement. 
        </p>
        <p>
          Fortunately, there's another way to deduce number of <i>gaps</i> in each subtree, based on binary tree invariants, that doesn't involve explicit counting. Those two important invariants are:
          <ul style="font-style: italic;">
            <li>If node \(X\) is the <i>left</i> child of node \(Y\), value of \(X\) is <i>less</i> than value of \(Y\)</li>
            <li>If node \(Z\) is the <i>right</i> child of node \(Y\), value of \(Z\) is <i>bigger</i> than value of \(Y\)</li>
          </ul>
        </p>
        <p>
          It may not be immediately obvious, but these two invariants can be generalized to make assertions on entire subtrees:
        </p>
        <ul style="font-style: italic;">
          <li> For every node \(X \,|\, X \in\) <i>left subtree</i> of \(Y\), value of \(X\) is <i>less</i> than value of \(Y\)</li>
          <li> For every node \(Z \,|\, Z \in\) <i>right subtree</i> of \(Y\), value of \(Z\) is <i>bigger</i> than value of \(Y\)</li>
        </ul>
        <p>
          This fact allows us to define bounding interval \(S\) recursively for each subtree. If you've been waiting for the punchline, this is it.
        </p>
        <p>
          Let \(y\) be the value of node \(Y\) and \(S_{y} = (Min, Max)\) be a bounding interval defining valid potential keys of subtree beginning at node \(Y\), then following two rules can be observed:
        </p>
          <ul style="font-style: italic;">
            <li>
              If node \(X\) is the <i>left</i> child of \(Y\), then bounding interval of \(X\) is \(S_{x} = (Min, y) \)
            </li>
            <li>
              If node \(Z\) is the <i>right</i> child of \(Y\), then bounding interval of \(Z\) is \(S_{z} = (y, Max) \)
            </li>
          </ul>
        <img src="boundaries.png" width="400px"/>
        <p>
          We will be referring to the above rules as <i>boundary propagation</i> rules, they allow us to construct set <i>boundary</i> \(S\) at each node, given we know <i>boundary</i> of it's parent. 
        </p>
        <p>
          Our <i>abstract gap search</i> algorithm relied on the fact that <i>gap count</i> is accessible at each node in <i>constant time</i>. Following from previous definitions, <i>gap count</i> is simply the <i>cardinality</i>(set size) of <i>complementary</i> set \(K'\), the set difference.
          \[\left| K' \right| = \left| \, S \setminus K \, \right| \]
        </p>
        <p>
          Cardinality of set difference is also, intuitively, same as difference of cardinalities. Making it possible to deduce cardinality of complementary set \(K'\) from cardinalities of sets \(S\) and \(K\):
          \[\left| K' \right| = \left| \, S \, \right| - \left| \, K \, \right| \]
        </p>
        <p font-style: italic;>
          The last statement can be more intuitively thought of as a difference between number of nodes tree can <i>potentially</i> have and number of nodes it <i>actually</i> has. That difference is the total number of gaps in a subtree:
        </p>
        <p class="statement">
          Number Of Gaps = Potential Size - Actual Size
        </p>
        <p>
          Where <i>actual size</i> is number of nodes augmented at each node, as described before and available in <i>constant time</i>. Potential size is simply size of <i>open interval</i> of valid possible keys.

          \[
          f \left(A,\,B \right) = \left\{\begin{array}{ll}
          B-A-1 & : A \lt B \\
          0 & : A = B
          \end{array}
          \right.
          \]
        </p>
        <p>
          We now have all the elements we need to turn the <i>abstract gap insertion</i> algorithm into a real one. We need to be able to calculate number of <i>gaps</i> in <i>constant time</i> at each node. Number of <i>gaps</i> can be <i>deduced</i> from <i>potential</i> and <i>actual size</i>. <i>Actual size</i> is already known and available in <i>constant time</i>. <i>Potential size</i> can be computed with a simple arithmetic function if the <i>bounding interval</i> is known. <i>Bounding intervals</i> itself can be propagated <i>recursively</i> to each node according to <i>propagation rules</i>.
        </p>
        <p>
          With that knowledge we can reshape our abstract gap insertion into something that can actually be represented on a computer: 
        </p>
<pre><code>
-- Pseudo-code for gap insertion using boundary propagation

Gap-Insert(Node, Min, Max) -> (Node, Key) {
  if (Gaps > 0):
    if (Node Is Leaf):
      Key = Any In Range (Min, Max)
      Return (Node(Left: Leaf, Key: Key, Right: Leaf, Size: 1), Key)
    else:
      (New-Left,  Left-Inserted-Key)  = Gap-Insert(Node.Left,  Min, Node.Key)
      (New-Right, Right-Inserted-Key) = Gap-Insert(Node.Right, Node.Key, Max)

      if (Left-Inserted-Key):
        Node.Size = New-Left.Size + 1 + Node.Right.Size
        Node.Left = New-Left;
      else:
        Node.Size = Node.Left.Size + 1 + New-Right.Size
        Node.Right = New-Right;
      
      Return (Node, Key)
  else:
    Return (Node, Key)

  where
    Gaps = Open-Interval-Size(Min, Max) - Node.Size 
}

</code></pre>
        <p>
          In pseudo-code presented above, insertion is attempted first to the <i>left</i>, then if that fails, to the <i>right</i>. 
          This new code structure makes sure that <i>gaps</i> are computed only once per node, for both leaf nodes and regular nodes. Boundary propagation rules are applied when passing new values for <i>Min</i> and <i>Max</i> in recursive calls.

          The code is structured assuming <i>lazy evaluation</i> is supported. If lazy evaluation is not available, regular conditional statements can be used. Using lazy evaluation makes for a much more graceful solution in this case, so it was preferred. 
        </p>
        <!-- Haskell implementation -->
        <pre>
          <code>
tr_gap_insert :: (Enum a, Eq a, RandomGen g) => g -> Tree a -> a -> a -> (g, Tree a, Maybe a)
tr_gap_insert g tr min max
  | space > 0 = 
      case tr of
        E ->
          let 
            k = middleEnum min max
            in (g, (T E k E 1), Just k)
        T l k r _ -> 
          let
            ns = tr_size(nl) + 1 + tr_size(nr)
            (eg, nl, nr, ik) = 
              let
                (bias, ng) = random g
                (lg, li, lik) = (tr_gap_insert ng l (min) (k))
                (rg, ri, rik) = (tr_gap_insert ng r (k) (max))
                left = (bias && isJust lik) || (not bias && isNothing rik)
              in
                if(left)
                  then (lg, li, r, lik) 
                  else (rg, l, ri, rik)
            in (eg, (T nl k nr ns), ik)
  | otherwise = (g, tr, Nothing)
  where
    space = (enumsBetween min max) - tr_size(tr)

</code></pre>

This is C implementation of gap insertion you can find the complete source code in files rbst.h and rbst.c.

<pre><code>
From file: rbst.c (<a href="rbst.html">view</a>)

int rbst_gap_insert(struct RBST* tree, void* value)
{
  assert(tree);
  assert(!tree->write_lock);
  
  // initial boundaries
  int min = tree->min;
  int max = tree->max;

  // check if tree has any gaps at all
  if((keys_between(min, max) - count(tree->root)) == 0)
  {
    return 0;
  }
  
  // handle special case when root is NULL
  if(tree->root == NULL)
  {
    int key = middle(min, max);
    tree->root = create_node(key, value);
    return key;
  }

  // find any node adjacent to a gap
  // store node at "it" and gap boundaries in "min", "max"
  int dir;
  struct RBSTNode* it = tree->root;
  for(;;) {
    int bias = rnd_bool();
    int gaps_left = keys_between(min, it->key) - count(it->links[0]);
    int gaps_right = keys_between(it->key, max) - count(it->links[1]);

    // select any branch having gaps, select randomly if both available
    dir = (!bias && !(gaps_left > 0)) || (bias && (gaps_right > 0));

    // apply boundary propagation rules
    if(!dir) 
      max = it->key; 
    else
      min = it->key;

    // increment actual size, since we know gap is available somewhere
    // and insertion is guaranteed to succeed along this path
    it->count++;

    // check if current node has open link on the side of gap
    if(it->links[dir] == NULL)
      break;

    // continue along branch where gaps are
    it = it->links[dir];
  }

  // select any key from the gap and create node there
  int key = middle(min, max);
  it->links[dir] = create_node(key, value);

  return key;
}
          </code>
        </pre>
      <!-- Okey, just be precise, define unique, what are we looking for etc. in terms of sets. Then define data structures briefly and show they normal form. Then show the modified form. That's all.  -->

      
      


        <!-- Introduction to current state of art
        Binary tree, skip lists all that jazz too
 -->
        <!-- Definitions
        What is unique, what are we looking for

        Gap Insertion For Skip lists
        Normal Insertion

        Gap Insertion For Binary trees
        Normal Insertion -->

        
      </div>
    </div>
  </body>
</html>

<!-- 
  
  Title
  Abstract
  Contents (Simple)
  MathJax
  Highlight.js

 


 -->
